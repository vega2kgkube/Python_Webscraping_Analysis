{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eda3f191",
   "metadata": {},
   "source": [
    "### TfidfVectorizer란?\n",
    "* TfidfVectorizer는 텍스트 데이터를 숫자로 변환해주는 도구입니다.\n",
    "* 머신러닝 모델은 텍스트를 직접 이해하지 못하므로, 단어의 중요도를 계산해 수치화합니다.\n",
    "    * 입력: 여러 문서 (예: 리뷰, 뉴스 기사)\n",
    "    * 출력: 각 문서를 단어 중요도로 표현된 숫자 벡터\n",
    "\n",
    "#### TfidfVectorizer를 왜 사용할까?\n",
    "* 텍스트 유사도 계산 (검색, 추천 시스템)\n",
    "* 스팸 메일 필터링 (중요 단어 탐지)\n",
    "* 감정 분석 (긍정/부정 키워드 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cee0683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['강아지' '고양이' '낮잠' '마시기' '반려동물' '우유' '자기']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.51785612, 0.51785612, 0.        , 0.        , 0.68091856,\n",
       "        0.        , 0.        ],\n",
       "       [0.4736296 , 0.        , 0.        , 0.62276601, 0.        ,\n",
       "        0.62276601, 0.        ],\n",
       "       [0.        , 0.4736296 , 0.62276601, 0.        , 0.        ,\n",
       "        0.        , 0.62276601]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "docs = [\n",
    "    \"강아지 고양이 반려동물\",  \n",
    "    \"강아지 우유 마시기\",  \n",
    "    \"고양이 낮잠 자기\"\n",
    "]\n",
    "\n",
    "# 1. TfidfVectorizer 적용\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(docs)\n",
    "\n",
    "# 2. 결과 (단어별 가중치)\n",
    "print(tfidf.get_feature_names_out())  \n",
    "# 출력: ['고양이', '낮잠', '마시기', '반려동물', '우유', '자기', '강아지']\n",
    "\n",
    "tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0b420",
   "metadata": {},
   "source": [
    "#### 한국어 텍스트 + 불용어 제거\n",
    "* 불용어(를, 은)가 제거된 순수 명사 중심의 가중치 계산."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b96dd145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 목록: ['강아지' '고양이' '고양이는' '낮잠을' '마신다' '반려동물' '우유를' '잔다']\n",
      "TF-IDF 행렬:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4736296 , 0.62276601, 0.        , 0.        , 0.        ,\n",
       "        0.62276601, 0.        , 0.        ],\n",
       "       [0.4736296 , 0.        , 0.        , 0.        , 0.62276601,\n",
       "        0.        , 0.62276601, 0.        ],\n",
       "       [0.        , 0.        , 0.57735027, 0.57735027, 0.        ,\n",
       "        0.        , 0.        , 0.57735027]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 한국어 문서\n",
    "docs = [\n",
    "    \"강아지 고양이 반려동물\",\n",
    "    \"강아지 우유를 마신다\",\n",
    "    \"고양이는 낮잠을 잔다\"\n",
    "]\n",
    "\n",
    "# 불용어 지정 (예: \"를\", \"은\" 같은 조사 제거)\n",
    "stop_words = [\"를\", \"은\", \"는\", \"을\"]\n",
    "\n",
    "# TF-IDF 변환 (불용어 제거 적용)\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words)\n",
    "tfidf_matrix = tfidf.fit_transform(docs)\n",
    "\n",
    "print(\"단어 목록:\", tfidf.get_feature_names_out())\n",
    "print(\"TF-IDF 행렬:\\n\")\n",
    "tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f223020",
   "metadata": {},
   "source": [
    "#### n-gram 적용 (연속된 단어 묶기)\n",
    "* \"machine learning\", \"love machine\" 같은 단어 쌍이 추가됩니다.\n",
    "* 문맥을 반영한 분석이 가능해집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a1d1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어/2-gram 목록: ['boring' 'boring lectures' 'fun' 'hate' 'hate boring' 'is' 'is fun'\n",
      " 'learning' 'learning is' 'lectures' 'love' 'love machine' 'machine'\n",
      " 'machine learning']\n",
      "TF-IDF 행렬:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.3935112 , 0.        , 0.        ,\n",
       "        0.51741994, 0.51741994, 0.3935112 , 0.3935112 ],\n",
       "       [0.4472136 , 0.4472136 , 0.        , 0.4472136 , 0.4472136 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.4472136 ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.41756662, 0.        , 0.        ,\n",
       "        0.41756662, 0.41756662, 0.31757018, 0.41756662, 0.        ,\n",
       "        0.        , 0.        , 0.31757018, 0.31757018]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "docs = [\n",
    "    \"I love machine learning\",\n",
    "    \"I hate boring lectures\",\n",
    "    \"machine learning is fun\"\n",
    "]\n",
    "\n",
    "# 2-gram 적용 (단어 2개씩 묶어서 처리)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 2))  # 1-gram과 2-gram 모두 사용\n",
    "tfidf_matrix = tfidf.fit_transform(docs)\n",
    "\n",
    "print(\"단어/2-gram 목록:\", tfidf.get_feature_names_out())\n",
    "print(\"TF-IDF 행렬:\\n\")\n",
    "tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949e012e",
   "metadata": {},
   "source": [
    "### TF-IDF란?\n",
    "##### TF (Term Frequency)\n",
    "* \"문서 내에서 단어가 얼마나 자주 등장하는지\"\n",
    "    * 예: \"강아지\"가 한 문서에서 5번 나오면 TF = 5\n",
    "##### IDF (Inverse Document Frequency)\n",
    "* \"모든 문서에서 그 단어가 흔한지 희귀한지\"\n",
    "    * 예: \"그리고\"는 모든 문서에 자주 나오므로 가중치 ↓\n",
    "    * \"반려동물\"은 특정 문서에만 나오면 가중치 ↑\n",
    "##### TF-IDF = TF × IDF\n",
    "* 자주 나오지만 특정 문서에 집중된 단어에 높은 점수 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9430b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이 제품 정말 좋아요! 강력 추천합니다.',\n",
       " '배송이 느렸지만 제품은 괜찮아요.',\n",
       " '가격 대비 성능이 아쉽습니다.',\n",
       " '완벽한 제품이에요. 다음에도 구매할 거예요!',\n",
       " '고객 서비스가 별로였어요.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 분석, 스팸 필터링 등에 사용 가능.\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# CSV 파일 로드 (예: 리뷰 데이터)\n",
    "data = pd.read_csv(\"data/reviews.csv\")  # \"text\" 컬럼에 텍스트가 있다고 가정\n",
    "texts = data[\"text\"].tolist()\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14cf2dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>가격</th>\n",
       "      <th>강력</th>\n",
       "      <th>거예요</th>\n",
       "      <th>고객</th>\n",
       "      <th>괜찮아요</th>\n",
       "      <th>구매할</th>\n",
       "      <th>느렸지만</th>\n",
       "      <th>다음에도</th>\n",
       "      <th>대비</th>\n",
       "      <th>배송이</th>\n",
       "      <th>...</th>\n",
       "      <th>서비스가</th>\n",
       "      <th>성능이</th>\n",
       "      <th>아쉽습니다</th>\n",
       "      <th>완벽한</th>\n",
       "      <th>정말</th>\n",
       "      <th>제품</th>\n",
       "      <th>제품은</th>\n",
       "      <th>제품이에요</th>\n",
       "      <th>좋아요</th>\n",
       "      <th>추천합니다</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    가격        강력       거예요       고객  괜찮아요       구매할  느렸지만      다음에도   대비  배송이  \\\n",
       "0  0.0  0.447214  0.000000  0.00000   0.0  0.000000   0.0  0.000000  0.0  0.0   \n",
       "1  0.0  0.000000  0.000000  0.00000   0.5  0.000000   0.5  0.000000  0.0  0.5   \n",
       "2  0.5  0.000000  0.000000  0.00000   0.0  0.000000   0.0  0.000000  0.5  0.0   \n",
       "3  0.0  0.000000  0.447214  0.00000   0.0  0.447214   0.0  0.447214  0.0  0.0   \n",
       "4  0.0  0.000000  0.000000  0.57735   0.0  0.000000   0.0  0.000000  0.0  0.0   \n",
       "\n",
       "   ...     서비스가  성능이  아쉽습니다       완벽한        정말        제품  제품은     제품이에요  \\\n",
       "0  ...  0.00000  0.0    0.0  0.000000  0.447214  0.447214  0.0  0.000000   \n",
       "1  ...  0.00000  0.0    0.0  0.000000  0.000000  0.000000  0.5  0.000000   \n",
       "2  ...  0.00000  0.5    0.5  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "3  ...  0.00000  0.0    0.0  0.447214  0.000000  0.000000  0.0  0.447214   \n",
       "4  ...  0.57735  0.0    0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
       "\n",
       "        좋아요     추천합니다  \n",
       "0  0.447214  0.447214  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.000000  \n",
       "3  0.000000  0.000000  \n",
       "4  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF 변환\n",
    "tfidf = TfidfVectorizer(max_features=100)  # 상위 100개 단어만 선택\n",
    "tfidf_matrix = tfidf.fit_transform(texts)\n",
    "\n",
    "# DataFrame으로 변환\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf.get_feature_names_out()\n",
    ")\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b3e333",
   "metadata": {},
   "source": [
    "#### 유사도 계산 (코사인 유사도)\n",
    "* 검색 엔진, 문서 클러스터링에서 유용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a6050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 유사도: 0.4112070550676187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 두 문서의 유사도 비교\n",
    "doc1 = \"I love python programming\"\n",
    "doc2 = \"Python programming is fun\"\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform([doc1, doc2])\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
    "print(\"문서 유사도:\", similarity[0][0])  # 0.41 (약 41% 유사)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
