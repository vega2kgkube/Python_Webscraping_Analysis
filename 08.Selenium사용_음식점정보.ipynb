{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import re\n",
    "import urllib.parse\n",
    "\n",
    "class RestaurantRatingCrawler:\n",
    "    def __init__(self, use_selenium=True):\n",
    "        \"\"\"음식점 평점 크롤러 초기화\"\"\"\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        })\n",
    "        \n",
    "        self.driver = None\n",
    "        if use_selenium:\n",
    "            self.setup_selenium()\n",
    "    \n",
    "    def setup_selenium(self):\n",
    "        \"\"\"Selenium 드라이버 설정\"\"\"\n",
    "        try:\n",
    "            chrome_options = Options()\n",
    "            chrome_options.add_argument('--headless')\n",
    "            chrome_options.add_argument('--no-sandbox')\n",
    "            chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "            chrome_options.add_argument('--disable-gpu')\n",
    "            chrome_options.add_argument('--window-size=1920,1080')\n",
    "            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')\n",
    "            \n",
    "            self.driver = webdriver.Chrome(options=chrome_options)\n",
    "            self.driver.implicitly_wait(10)\n",
    "            print(\"Selenium 드라이버 초기화 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"Selenium 설정 실패: {e}\")\n",
    "    \n",
    "    # 1. 네이버 플레이스 크롤링\n",
    "    def crawl_naver_place(self, search_keyword, max_results=50):\n",
    "        \"\"\"네이버 플레이스에서 음식점 정보 크롤링\"\"\"\n",
    "        restaurants = []\n",
    "        \n",
    "        try:\n",
    "            if not self.driver:\n",
    "                print(\"Selenium 드라이버가 필요합니다.\")\n",
    "                return restaurants\n",
    "            \n",
    "            # 네이버 지도 검색\n",
    "            search_url = f\"https://map.naver.com/p/search/{urllib.parse.quote(search_keyword)}\"\n",
    "            self.driver.get(search_url)\n",
    "            time.sleep(3)\n",
    "            \n",
    "            # 검색 결과 프레임으로 전환\n",
    "            try:\n",
    "                search_iframe = WebDriverWait(self.driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.ID, \"searchIframe\"))\n",
    "                )\n",
    "                self.driver.switch_to.frame(search_iframe)\n",
    "            except:\n",
    "                print(\"검색 프레임을 찾을 수 없습니다.\")\n",
    "                return restaurants\n",
    "            \n",
    "            # 결과 수집\n",
    "            collected = 0\n",
    "            scroll_count = 0\n",
    "            max_scroll = 10\n",
    "            \n",
    "            while collected < max_results and scroll_count < max_scroll:\n",
    "                # 음식점 리스트 요소들 찾기\n",
    "                restaurant_elements = self.driver.find_elements(By.CSS_SELECTOR, \"li[data-id]\")\n",
    "                \n",
    "                for element in restaurant_elements[collected:]:\n",
    "                    try:\n",
    "                        restaurant_info = self.extract_naver_restaurant_info(element)\n",
    "                        if restaurant_info:\n",
    "                            restaurants.append(restaurant_info)\n",
    "                            collected += 1\n",
    "                            \n",
    "                        if collected >= max_results:\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        print(f\"네이버 플레이스 정보 추출 실패: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                # 스크롤하여 더 많은 결과 로드\n",
    "                self.driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", \n",
    "                                         self.driver.find_element(By.CSS_SELECTOR, \".scroll_box\"))\n",
    "                time.sleep(2)\n",
    "                scroll_count += 1\n",
    "            \n",
    "            self.driver.switch_to.default_content()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"네이버 플레이스 크롤링 오류: {e}\")\n",
    "        \n",
    "        return restaurants\n",
    "    \n",
    "    def extract_naver_restaurant_info(self, element):\n",
    "        \"\"\"네이버 플레이스 음식점 정보 추출\"\"\"\n",
    "        try:\n",
    "            # 음식점명\n",
    "            name_elem = element.find_element(By.CSS_SELECTOR, \".place_bluelink\")\n",
    "            name = name_elem.text.strip()\n",
    "            \n",
    "            # 평점\n",
    "            try:\n",
    "                rating_elem = element.find_element(By.CSS_SELECTOR, \".rating_real\")\n",
    "                rating = rating_elem.text.strip()\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            \n",
    "            # 리뷰 수\n",
    "            try:\n",
    "                review_elem = element.find_element(By.CSS_SELECTOR, \".rating_real + span\")\n",
    "                review_count = review_elem.text.strip()\n",
    "            except:\n",
    "                review_count = \"N/A\"\n",
    "            \n",
    "            # 카테고리\n",
    "            try:\n",
    "                category_elem = element.find_element(By.CSS_SELECTOR, \".category\")\n",
    "                category = category_elem.text.strip()\n",
    "            except:\n",
    "                category = \"N/A\"\n",
    "            \n",
    "            # 주소\n",
    "            try:\n",
    "                address_elem = element.find_element(By.CSS_SELECTOR, \".addr\")\n",
    "                address = address_elem.text.strip()\n",
    "            except:\n",
    "                address = \"N/A\"\n",
    "            \n",
    "            return {\n",
    "                'name': name,\n",
    "                'rating': rating,\n",
    "                'review_count': review_count,\n",
    "                'category': category,\n",
    "                'address': address,\n",
    "                'source': 'naver'\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"네이버 정보 추출 실패: {e}\")\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    # 3. 식신 크롤링\n",
    "    def crawl_siksinhot(self, search_keyword, max_results=30):\n",
    "        \"\"\"식신 사이트 크롤링\"\"\"\n",
    "        restaurants = []\n",
    "        \n",
    "        try:\n",
    "            if not self.driver:\n",
    "                print(\"Selenium 드라이버가 필요합니다.\")\n",
    "                return restaurants\n",
    "            \n",
    "            # 식신 검색 페이지\n",
    "            search_url = f\"https://www.siksinhot.com/search?keywords={urllib.parse.quote(search_keyword)}\"\n",
    "            self.driver.get(search_url)\n",
    "            time.sleep(3)\n",
    "            \n",
    "            # 음식점 리스트 수집\n",
    "            collected = 0\n",
    "            while collected < max_results:\n",
    "                restaurant_elements = self.driver.find_elements(By.CSS_SELECTOR, \".item_list li\")\n",
    "                \n",
    "                for element in restaurant_elements[collected:]:\n",
    "                    try:\n",
    "                        restaurant_info = self.extract_siksinhot_info(element)\n",
    "                        if restaurant_info:\n",
    "                            restaurants.append(restaurant_info)\n",
    "                            collected += 1\n",
    "                            \n",
    "                        if collected >= max_results:\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        print(f\"식신 정보 추출 실패: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                # 더보기 버튼 클릭 또는 페이지 이동\n",
    "                try:\n",
    "                    more_button = self.driver.find_element(By.CSS_SELECTOR, \".btn_more\")\n",
    "                    if more_button.is_displayed():\n",
    "                        more_button.click()\n",
    "                        time.sleep(2)\n",
    "                    else:\n",
    "                        break\n",
    "                except:\n",
    "                    break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"식신 크롤링 오류: {e}\")\n",
    "        \n",
    "        return restaurants\n",
    "    \n",
    "    def extract_siksinhot_info(self, element):\n",
    "        \"\"\"식신 음식점 정보 추출\"\"\"\n",
    "        try:\n",
    "            name_elem = element.find_element(By.CSS_SELECTOR, \".store_name\")\n",
    "            name = name_elem.text.strip()\n",
    "            \n",
    "            try:\n",
    "                rating_elem = element.find_element(By.CSS_SELECTOR, \".rate_point\")\n",
    "                rating = rating_elem.text.strip()\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                category_elem = element.find_element(By.CSS_SELECTOR, \".category\")\n",
    "                category = category_elem.text.strip()\n",
    "            except:\n",
    "                category = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                address_elem = element.find_element(By.CSS_SELECTOR, \".address\")\n",
    "                address = address_elem.text.strip()\n",
    "            except:\n",
    "                address = \"N/A\"\n",
    "            \n",
    "            return {\n",
    "                'name': name,\n",
    "                'rating': rating,\n",
    "                'category': category,\n",
    "                'address': address,\n",
    "                'source': 'siksinhot'\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"식신 정보 추출 실패: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # 4. 카카오맵 크롤링\n",
    "    def crawl_kakao_map(self, search_keyword, max_results=40):\n",
    "        \"\"\"카카오맵에서 음식점 정보 크롤링\"\"\"\n",
    "        restaurants = []\n",
    "        \n",
    "        try:\n",
    "            if not self.driver:\n",
    "                print(\"Selenium 드라이버가 필요합니다.\")\n",
    "                return restaurants\n",
    "            \n",
    "            # 카카오맵 검색\n",
    "            search_url = f\"https://map.kakao.com/?q={urllib.parse.quote(search_keyword)}\"\n",
    "            self.driver.get(search_url)\n",
    "            time.sleep(3)\n",
    "            \n",
    "            collected = 0\n",
    "            page = 1\n",
    "            \n",
    "            while collected < max_results and page <= 5:  # 최대 5페이지\n",
    "                # 검색 결과 요소들 찾기\n",
    "                restaurant_elements = self.driver.find_elements(By.CSS_SELECTOR, \".placelist > .PlaceItem\")\n",
    "                \n",
    "                for element in restaurant_elements:\n",
    "                    try:\n",
    "                        restaurant_info = self.extract_kakao_restaurant_info(element)\n",
    "                        if restaurant_info:\n",
    "                            restaurants.append(restaurant_info)\n",
    "                            collected += 1\n",
    "                            \n",
    "                        if collected >= max_results:\n",
    "                            break\n",
    "                    except Exception as e:\n",
    "                        print(f\"카카오맵 정보 추출 실패: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                # 다음 페이지로 이동\n",
    "                try:\n",
    "                    next_button = self.driver.find_element(By.ID, f\"info\\\\.search\\\\.page\\\\.next\")\n",
    "                    if next_button.is_enabled():\n",
    "                        next_button.click()\n",
    "                        time.sleep(2)\n",
    "                        page += 1\n",
    "                    else:\n",
    "                        break\n",
    "                except:\n",
    "                    break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"카카오맵 크롤링 오류: {e}\")\n",
    "        \n",
    "        return restaurants\n",
    "    \n",
    "    def extract_kakao_restaurant_info(self, element):\n",
    "        \"\"\"카카오맵 음식점 정보 추출\"\"\"\n",
    "        try:\n",
    "            name_elem = element.find_element(By.CSS_SELECTOR, \".link_name\")\n",
    "            name = name_elem.text.strip()\n",
    "            \n",
    "            try:\n",
    "                rating_elem = element.find_element(By.CSS_SELECTOR, \".rating .num\")\n",
    "                rating = rating_elem.text.strip()\n",
    "            except:\n",
    "                rating = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                category_elem = element.find_element(By.CSS_SELECTOR, \".subcategory\")\n",
    "                category = category_elem.text.strip()\n",
    "            except:\n",
    "                category = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                address_elem = element.find_element(By.CSS_SELECTOR, \".addr\")\n",
    "                address = address_elem.text.strip()\n",
    "            except:\n",
    "                address = \"N/A\"\n",
    "            \n",
    "            return {\n",
    "                'name': name,\n",
    "                'rating': rating,\n",
    "                'category': category,\n",
    "                'address': address,\n",
    "                'source': 'kakaomap'\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"카카오맵 정보 추출 실패: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # 데이터 통합 및 저장\n",
    "    def crawl_all_sources(self, search_keyword, max_results_per_source=30):\n",
    "        \"\"\"모든 소스에서 데이터 수집\"\"\"\n",
    "        all_restaurants = []\n",
    "        \n",
    "        print(\"=== 네이버 플레이스 크롤링 시작 ===\")\n",
    "        naver_data = self.crawl_naver_place(search_keyword, max_results_per_source)\n",
    "        all_restaurants.extend(naver_data)\n",
    "        print(f\"네이버 플레이스: {len(naver_data)}개 수집\")\n",
    "        \n",
    "        print(\"=== 카카오맵 크롤링 시작 ===\")\n",
    "        kakao_data = self.crawl_kakao_map(search_keyword, max_results_per_source)\n",
    "        all_restaurants.extend(kakao_data)\n",
    "        print(f\"카카오맵: {len(kakao_data)}개 수집\")\n",
    "        \n",
    "        print(\"=== 식신 크롤링 시작 ===\")\n",
    "        siksinhot_data = self.crawl_siksinhot(search_keyword, max_results_per_source)\n",
    "        all_restaurants.extend(siksinhot_data)\n",
    "        print(f\"식신: {len(siksinhot_data)}개 수집\")\n",
    "                \n",
    "        return all_restaurants\n",
    "    \n",
    "    def remove_duplicates(self, restaurants):\n",
    "        \"\"\"중복 음식점 제거\"\"\"\n",
    "        seen_names = set()\n",
    "        unique_restaurants = []\n",
    "        \n",
    "        for restaurant in restaurants:\n",
    "            name_normalized = re.sub(r'[^\\w가-힣]', '', restaurant['name']).lower()\n",
    "            if name_normalized not in seen_names:\n",
    "                seen_names.add(name_normalized)\n",
    "                unique_restaurants.append(restaurant)\n",
    "        \n",
    "        return unique_restaurants\n",
    "    \n",
    "    def save_to_csv(self, data, filename=\"data/restaurant_ratings.csv\"):\n",
    "        \"\"\"CSV 파일로 저장\"\"\"\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"데이터가 {filename}에 저장되었습니다.\")\n",
    "    \n",
    "    def save_to_json(self, data, filename=\"data/restaurant_ratings.json\"):\n",
    "        \"\"\"JSON 파일로 저장\"\"\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"데이터가 {filename}에 저장되었습니다.\")\n",
    "    \n",
    "    def analyze_ratings(self, restaurants):\n",
    "        \"\"\"평점 데이터 분석\"\"\"\n",
    "        df = pd.DataFrame(restaurants)\n",
    "        \n",
    "        # 평점을 숫자로 변환\n",
    "        def extract_rating(rating_str):\n",
    "            if rating_str == \"N/A\":\n",
    "                return None\n",
    "            \n",
    "            # 숫자만 추출\n",
    "            numbers = re.findall(r'\\d+\\.?\\d*', str(rating_str))\n",
    "            if numbers:\n",
    "                return float(numbers[0])\n",
    "            return None\n",
    "        \n",
    "        df['rating_numeric'] = df['rating'].apply(extract_rating)\n",
    "        \n",
    "        # 통계 정보 출력\n",
    "        print(\"\\n=== 평점 데이터 분석 ===\")\n",
    "        print(f\"전체 음식점 수: {len(df)}\")\n",
    "        print(f\"평점 데이터가 있는 음식점: {df['rating_numeric'].notna().sum()}개\")\n",
    "        \n",
    "        if df['rating_numeric'].notna().any():\n",
    "            print(f\"평균 평점: {df['rating_numeric'].mean():.2f}\")\n",
    "            print(f\"최고 평점: {df['rating_numeric'].max():.2f}\")\n",
    "            print(f\"최저 평점: {df['rating_numeric'].min():.2f}\")\n",
    "            \n",
    "            # 소스별 통계\n",
    "            print(\"\\n=== 소스별 통계 ===\")\n",
    "            source_stats = df.groupby('source')['rating_numeric'].agg(['count', 'mean']).round(2)\n",
    "            print(source_stats)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"리소스 정리\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            print(\"드라이버가 종료되었습니다.\")\n",
    "\n",
    "# 메인 실행 함수\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    crawler = RestaurantRatingCrawler()\n",
    "    \n",
    "    try:\n",
    "        # 검색 키워드 설정\n",
    "        search_keyword = \"강남 맛집\"  # 원하는 검색어로 변경\n",
    "        \n",
    "        print(f\"'{search_keyword}' 검색 시작...\")\n",
    "        \n",
    "        # 모든 소스에서 데이터 수집\n",
    "        all_restaurants = crawler.crawl_all_sources(search_keyword, max_results_per_source=20)\n",
    "        \n",
    "        # 중복 제거\n",
    "        unique_restaurants = crawler.remove_duplicates(all_restaurants)\n",
    "        \n",
    "        print(f\"\\n총 {len(all_restaurants)}개 수집, 중복 제거 후 {len(unique_restaurants)}개\")\n",
    "        \n",
    "        # 결과 미리보기\n",
    "        print(\"\\n=== 수집된 음식점 예시 ===\")\n",
    "        for i, restaurant in enumerate(unique_restaurants[:5]):\n",
    "            print(f\"\\n{i+1}. {restaurant['name']}\")\n",
    "            print(f\"   평점: {restaurant['rating']}\")\n",
    "            print(f\"   카테고리: {restaurant['category']}\")\n",
    "            print(f\"   주소: {restaurant['address']}\")\n",
    "            print(f\"   출처: {restaurant['source']}\")\n",
    "        \n",
    "        # 데이터 분석\n",
    "        df = crawler.analyze_ratings(unique_restaurants)\n",
    "        \n",
    "        # 데이터 저장\n",
    "        if unique_restaurants:\n",
    "            crawler.save_to_csv(unique_restaurants)\n",
    "            crawler.save_to_json(unique_restaurants)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"크롤링 실행 중 오류: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        crawler.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# 간단한 사용 예시\n",
    "\"\"\"\n",
    "# 특정 소스만 사용하는 경우\n",
    "crawler = RestaurantRatingCrawler()\n",
    "\n",
    "# 네이버 플레이스만 크롤링\n",
    "naver_restaurants = crawler.crawl_naver_place(\"홍대 맛집\", 30)\n",
    "\n",
    "# 카카오맵만 크롤링  \n",
    "kakao_restaurants = crawler.crawl_kakao_map(\"이태원 맛집\", 30)\n",
    "\n",
    "# 결과 저장\n",
    "all_data = naver_restaurants + kakao_restaurants\n",
    "crawler.save_to_csv(all_data, \"my_restaurants.csv\")\n",
    "\n",
    "crawler.close()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
